{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6c3ade9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<wandb.apis.public.api.Api object at 0x7fa2f0e0b3d0>\n",
      "x2hzde8t\n",
      "<Runs jingchuan0guan-the-university-of-tokyo-hospital/hippo>\n",
      "0 bxdoprfi\n",
      "<Run jingchuan0guan-the-university-of-tokyo-hospital/hippo/bxdoprfi (finished)>\n",
      "<Artifact QXJ0aWZhY3Q6MTU4MjYzMzQyOQ==>\n",
      "1 wxox9i81\n",
      "<Run jingchuan0guan-the-university-of-tokyo-hospital/hippo/wxox9i81 (finished)>\n",
      "<Artifact QXJ0aWZhY3Q6MTY0NTIxMTYzMQ==>\n",
      "2 u4c4hkof\n",
      "<Run jingchuan0guan-the-university-of-tokyo-hospital/hippo/u4c4hkof (finished)>\n",
      "<Artifact QXJ0aWZhY3Q6MTY0OTMyOTU1MQ==>\n"
     ]
    }
   ],
   "source": [
    "import torch, wandb\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=np.inf, precision=10, linewidth=10**4)\n",
    "torch.set_printoptions(threshold=np.inf, precision=10, linewidth=10**4)\n",
    "api = wandb.Api()\n",
    "print(api)\n",
    "\n",
    "project_name = 'hippo'\n",
    "run_id = wandb.run.id  # 現在のランIDを取得\n",
    "print(run_id)\n",
    "\n",
    "runs = api.runs(project_name)\n",
    "print(runs)\n",
    "\n",
    "for idx, run in enumerate(runs):\n",
    "    print(idx, run.id)\n",
    "    print(run)\n",
    "    metrics = run.history()\n",
    "    # for rep, met in enumerate(metrics):\n",
    "    #     print(met)\n",
    "    \n",
    "    artifacts = run.logged_artifacts()  # ランに関連する全てのアーティファクト\n",
    "    for artifact in artifacts:\n",
    "        print(artifact)\n",
    "        if 'model' in artifact.name.lower():  # モデルアーティファクトを特定する\n",
    "            print(f\"Artifact Name: {artifact.name}\")\n",
    "            print(f\"Artifact Type: {artifact.type}\")\n",
    "            print(f\"Artifact Metadata: {artifact.metadata}\")  # メタデータにモデルに関する情報が含まれていることがあります\n",
    "    if idx==2:\n",
    "        break\n",
    "\n",
    "# run = api.run(\"ユーザー名/プロジェクト名/ランID\")\n",
    "# artifact = run.use_artifact(\"モデル名:latest\") #（例：last.ckpt）\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "# model = MyModel.load_from_checkpoint(artifact_dir + \"/last.ckpt\") # モデル読み込み（Lightningなど使ってるなら）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf86f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hydra.main(config_path=\"./configs/model/\", config_name=\"s4d\", version_base=None)\n",
    "# def get_model(model_config: DictConfig):\n",
    "#     print(model_config)  # DictConfigとしてアクセス可能\n",
    "#     for key in model_config.keys():\n",
    "#         print(key, model_config[key])\n",
    "#     model = utils.instantiate(registry.model, model_config)#.load_from_checkpoint(\"path/to/model.ckpt\")\n",
    "#     print(model)\n",
    "    \n",
    "#     state_dict = model.state_dict()\n",
    "#     for k, v in state_dict.items():\n",
    "#         print(k, v.shape)\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('/home/kan/ML_application/s4/src')\n",
    "# layer_key = [\"s4d\", ][0]\n",
    "# print(registry.model[\"model\"])\n",
    "# print(registry.layer[layer_key])\n",
    "# print(registry.model[\"model\"](layer=registry.layer[layer_key]))\n",
    "# ckpt ファイルをロード\n",
    "# model = utils.instantiate(registry.model, layer=\"s4d\", )\n",
    "# registry.model[\"model\"](layer=layer).load_from_checkpoint(\"path/to/model.ckpt\")\n",
    "\n",
    "# for root, dirs, files in os.walk(base_dir):\n",
    "#     # 今の階層の深さを数える\n",
    "#     depth = root[len(base_dir):].count(os.sep)\n",
    "#     print(depth)\n",
    "#     if depth > max_depth:\n",
    "#         # さらに深い階層の探索をやめる\n",
    "#         dirs[:] = []\n",
    "#         continue\n",
    "\n",
    "#     for file in files:\n",
    "#         print(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8bd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kan/ML_application/s4/outputs/2025-04-20/22-59-56\n",
      "/home/kan/ML_application/s4/outputs/2025-04-20/22-59-56/checkpoints/last.ckpt\n",
      "outputs/2025-04-20/22-59-56/.hydra\n",
      "cfg {'train': {'seed': 0, 'interval': 'epoch', 'monitor': 'val/accuracy', 'mode': 'max', 'ema': 0.0, 'test': False, 'debug': False, 'ignore_warnings': False, 'state': {'mode': None, 'chunk_len': None, 'overlap_len': None, 'n_context': 0, 'n_context_eval': '${.n_context}'}, 'sweep': None, 'group': None, 'benchmark_step': False, 'benchmark_step_k': 1, 'benchmark_step_T': 1, 'checkpoint_path': None, 'visualizer': 'filters', 'disable_dataset': False}, 'wandb': {'project': 'hippo', 'group': '', 'job_type': 'training', 'mode': 'online', 'save_dir': None, 'id': None}, 'trainer': {'accelerator': 'cuda', 'devices': [0, 1, 2, 3, 4, 5, 6, 7], 'accumulate_grad_batches': 1, 'max_epochs': 100, 'gradient_clip_val': 0.0, 'log_every_n_steps': 10, 'limit_train_batches': 1.0, 'limit_val_batches': 1.0, 'enable_progress_bar': True}, 'loader': {'batch_size': 16, 'num_workers': 4, 'pin_memory': True, 'drop_last': True, 'train_resolution': 1, 'eval_resolutions': [1]}, 'dataset': {'_name_': 'pathfinder', 'resolution': 128, 'sequential': True, 'tokenize': False, 'pool': 1, 'val_split': 0.1, 'test_split': 0.1, 'seed': 42, '__l_max': '${eval:${.resolution}**2 // ${.pool}**2}'}, 'task': {'_name_': 'base', 'loss': 'cross_entropy', 'metrics': ['accuracy'], 'torchmetrics': None}, 'optimizer': {'_name_': 'adamw', 'lr': 0.0005, 'weight_decay': 0.0}, 'scheduler': {'_name_': 'plateau', 'mode': '${train.mode}', 'factor': 0.2, 'patience': 40, 'min_lr': 0.0}, 'encoder': 'linear', 'decoder': {'_name_': 'sequence', 'mode': 'pool'}, 'model': {'layer': {'_name_': 's4d', 'd_state': 64, 'channels': 1, 'bidirectional': False, 'activation': 'gelu', 'postact': None, 'dropout': '${..dropout}', 'imag_scaling': 'linear', 'dt_min': 0.001, 'dt_max': 0.1, 'lr': 0.001, 'n_ssm': 1}, '_name_': 'model', 'prenorm': True, 'transposed': True, 'n_layers': 6, 'd_model': 256, 'residual': 'R', 'pool': {'_name_': 'sample', 'stride': 1, 'expand': 1}, 'norm': 'batch', 'dropout': 0.0}, 'callbacks': {'learning_rate_monitor': {'logging_interval': '${train.interval}'}, 'timer': {'step': True, 'inter_step': False, 'epoch': True, 'val': True}, 'params': {'total': True, 'trainable': True, 'fixed': True}, 'model_checkpoint': {'monitor': '${train.monitor}', 'mode': '${train.mode}', 'save_top_k': 1, 'save_last': True, 'dirpath': 'checkpoints/', 'filename': '${train.monitor}', 'auto_insert_metric_name': False, 'verbose': True}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_649803/159137829.py:14: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with initialize(config_path=cfg_path):\n"
     ]
    },
    {
     "ename": "InstantiationException",
     "evalue": "Cannot instantiate config of type type.\nTop level config must be an OmegaConf DictConfig/ListConfig object,\na plain dict/list, or a Structured Config class or instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInstantiationException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m cfg_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(relative_path)\u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/.hydra\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(cfg_path)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mcheck_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[75], line 23\u001b[0m, in \u001b[0;36mcheck_model\u001b[0;34m(model_name, cfg_name, cfg_path, model_path)\u001b[0m\n\u001b[1;32m     19\u001b[0m ModelClass \u001b[38;5;241m=\u001b[39m hydra\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mget_class(registry\u001b[38;5;241m.\u001b[39mmodel[model_name])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# model = ModelClass(cfg)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# model = instantiate(cfg.model) # registry.model,\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43minstantiate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mModelClass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# モデル構造のインスタンス化（この時点でランダム初期化）\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(model)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m(model))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.20/lib/python3.8/site-packages/hydra/_internal/instantiate/_instantiate2.py:253\u001b[0m, in \u001b[0;36minstantiate\u001b[0;34m(config, *args, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instantiate_node(\n\u001b[1;32m    250\u001b[0m         config, \u001b[38;5;241m*\u001b[39margs, recursive\u001b[38;5;241m=\u001b[39m_recursive_, convert\u001b[38;5;241m=\u001b[39m_convert_, partial\u001b[38;5;241m=\u001b[39m_partial_\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InstantiationException(\n\u001b[1;32m    254\u001b[0m         dedent(\n\u001b[1;32m    255\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124m            Cannot instantiate config of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(config)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124m            Top level config must be an OmegaConf DictConfig/ListConfig object,\u001b[39m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;124m            a plain dict/list, or a Structured Config class or instance.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         )\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mInstantiationException\u001b[0m: Cannot instantiate config of type type.\nTop level config must be an OmegaConf DictConfig/ListConfig object,\na plain dict/list, or a Structured Config class or instance."
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import LightningModule\n",
    "# import src.utils as utils\n",
    "from pathlib import Path\n",
    "\n",
    "import hydra\n",
    "from hydra import initialize, compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "# from hydra.utils import instantiate\n",
    "\n",
    "from src.utils import registry, instantiate\n",
    "\n",
    "def check_model(model_name=\"model\", cfg_name=\"config\", cfg_path=\"./configs/model/\",  model_path=\"\", ):\n",
    "    with initialize(config_path=cfg_path):\n",
    "        cfg = compose(config_name=cfg_name)\n",
    "    print(\"cfg\", cfg)\n",
    "    OmegaConf.set_struct(cfg, False)\n",
    "    # cfg.model._target_ = \"torch.nn.Identity\" \n",
    "    ModelClass = hydra.utils.get_class(registry.model[model_name])\n",
    "    # model = ModelClass(cfg)\n",
    "    \n",
    "    # model = instantiate(cfg.model) # registry.model,\n",
    "    model = instantiate(registry.model, cfg) # モデル構造のインスタンス化（この時点でランダム初期化）\n",
    "    print(model)\n",
    "    print(\"type\", type(model))\n",
    "    ckpt = torch.load(model_path, map_location=\"cpu\")# チェックポイントからstate_dictを読み込み\n",
    "    # state_dict = {k.replace(\"model.\", \"\"): v for k, v in ckpt[\"state_dict\"].items()}\n",
    "    # model.load_state_dict(state_dict)\n",
    "    print(\"Checkpoint keys:\", ckpt.keys())  # 追加\n",
    "    \n",
    "    state_dict = ckpt.get(\"state_dict\", ckpt)\n",
    "    model.load_state_dict(state_dict)\n",
    "    # if \"state_dict\" in ckpt:\n",
    "    #     state_dict = ckpt[\"state_dict\"]\n",
    "    # else:\n",
    "    #     state_dict = ckpt\n",
    "    # model.load_state_dict(state_dict)\n",
    "    \n",
    "    # for key in cfg.keys():\n",
    "    #     print(key, cfg[key])\n",
    "    # model = utils.instantiate(registry.model, cfg).load_from_checkpoint(model_path)\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "# /home/kan/ML_application/s4/outputs/2025-04-21/11-19-18/checkpoints/\n",
    "\n",
    "base_dir = \"/home/kan/ML_application/s4/outputs/\"\n",
    "max_depth = 2\n",
    "\n",
    "base_dir_ = Path(base_dir)\n",
    "for file in base_dir_.glob(\"*/*/checkpoints/*\"):\n",
    "    if file.is_file():\n",
    "        parent_path = file.parents[1]\n",
    "        print(parent_path)\n",
    "        print(file)\n",
    "        relative_path = parent_path.parts[parent_path.parts.index(\"outputs\"):]  # s4 以降の部分を抽出\n",
    "        cfg_path = \"/\".join(relative_path)+ \"/.hydra\"\n",
    "        print(cfg_path)\n",
    "        check_model(model_name=\"model\", cfg_path=cfg_path, model_path=file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08d7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8.20",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

# _target_: pytorch_lightning.Trainer

accelerator: "cuda"
# gpus: 1 # set `1` to train on GPU, `0` to train on CPU only
devices: [0,1,2,3, 4,5,6,7] #7 # plugins: "ddp"
# accelerator: ddp # controlled by train.ddp instead

accumulate_grad_batches: 1
max_epochs: 200
gradient_clip_val: 0.0

log_every_n_steps: 10
limit_train_batches: 1.0  # train on full dataset, can be used to toggle quick run
limit_val_batches: 1.0  # train on full dataset, can be used to toggle quick run
# weights_summary: top # Set to 'full' to see every layer
# progress_bar_refresh_rate: 1
enable_progress_bar: True
# track_grad_norm: 2 # Set to 2 to track norms of gradients, set to -1 not to track 
# resume_from_checkpoint: null
